{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ad71d0-355e-41df-8984-77c2e990c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbf83f7-2270-45c0-a1f5-5d7e29784962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/17 15:03:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66d1e8c-74b7-43d1-a3e1-4cceae19233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = [(\"2014-02-28\", \"2014-02-28 10:00:00.123\"),\n",
    "                     (\"2016-02-29\", \"2016-02-29 08:08:08.999\"),\n",
    "                     (\"2017-10-31\", \"2017-12-31 11:59:59.123\"),\n",
    "                     (\"2019-11-30\", \"2019-08-31 00:00:00.000\")\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2388d2be-84d9-4dd0-8823-bd08635795e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimesDF = spark.createDataFrame(datetimes).toDF('date','timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14cc4f43-2514-41a4-91ad-eeb5da421ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|date      |timestamp              |\n",
      "+----------+-----------------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|\n",
      "|2016-02-29|2016-02-29 08:08:08.999|\n",
      "|2017-10-31|2017-12-31 11:59:59.123|\n",
      "|2019-11-30|2019-08-31 00:00:00.000|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea14599e-44eb-4e4e-b614-0a6f1557d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+----------+---------------+-------------------+--------------------+\n",
      "|date      |timestamp              |trunc date|trunc timestamp|date trunc date    |date trunc timestamp|\n",
      "+----------+-----------------------+----------+---------------+-------------------+--------------------+\n",
      "|2014-02-28|2014-02-28 10:00:00.123|2014-01-01|2014-02-01     |2014-02-01 00:00:00|2014-02-28 00:00:00 |\n",
      "|2016-02-29|2016-02-29 08:08:08.999|2016-01-01|2016-02-01     |2016-02-01 00:00:00|2016-02-29 00:00:00 |\n",
      "|2017-10-31|2017-12-31 11:59:59.123|2017-01-01|2017-12-01     |2017-10-01 00:00:00|2017-12-31 00:00:00 |\n",
      "|2019-11-30|2019-08-31 00:00:00.000|2019-01-01|2019-08-01     |2019-11-01 00:00:00|2019-08-31 00:00:00 |\n",
      "+----------+-----------------------+----------+---------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.withColumn('trunc date',trunc('date','yy')). \\\n",
    "            withColumn('trunc timestamp',trunc('timestamp','MM')). \\\n",
    "            withColumn('date trunc date',date_trunc('MM','date')). \\\n",
    "            withColumn('date trunc timestamp',date_trunc('dd','timestamp')). \\\n",
    "            show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6072d42b-7a76-41d1-8e6b-79b662b44260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+\n",
      "|      date|           timestamp|    date trunc hour|\n",
      "+----------+--------------------+-------------------+\n",
      "|2014-02-28|2014-02-28 10:00:...|2014-02-28 00:00:00|\n",
      "|2016-02-29|2016-02-29 08:08:...|2016-02-29 00:00:00|\n",
      "|2017-10-31|2017-12-31 11:59:...|2017-10-31 00:00:00|\n",
      "|2019-11-30|2019-08-31 00:00:...|2019-11-30 00:00:00|\n",
      "+----------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datetimesDF.withColumn('date trunc hour',date_trunc('HOUR','date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9e635-1da5-4558-ba29-79f7fdd41b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
